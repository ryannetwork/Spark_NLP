{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Spark NLP\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "import sparknlp\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Start Spark Session with Spark NLP\n",
    "#spark = sparknlp.start()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[4]\")\\\n",
    "    .config(\"spark.driver.memory\",\"4G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"2G\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.4.5\")\\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"1000M\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Spam Case Data (5k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# File location and type\n",
    "file_location = r'E:\\Machine Learning\\data\\Spam_data.csv'\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "\n",
    "\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)\n",
    "\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 3964\n",
      "Test Dataset Count: 1610\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = df.randomSplit([0.7, 0.3], seed = 100)\n",
    "\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Category', 'Message']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and ML Pipeline using Spark-NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1610"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, OneHotEncoder, StringIndexer, VectorAssembler, SQLTransformer,IndexToString\n",
    "from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"Message\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "    \n",
    "tokenizer = Tokenizer() \\\n",
    "  .setInputCols([\"document\"]) \\\n",
    "  .setOutputCol(\"token\")\n",
    "    \n",
    "normalizer = Normalizer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"normalized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner()\\\n",
    "      .setInputCols(\"normalized\")\\\n",
    "      .setOutputCol(\"cleanTokens\")\\\n",
    "      .setCaseSensitive(False)\n",
    "\n",
    "stemmer = Stemmer() \\\n",
    "    .setInputCols([\"cleanTokens\"]) \\\n",
    "    .setOutputCol(\"stem\")\n",
    "\n",
    "finisher = Finisher() \\\n",
    "    .setInputCols([\"stem\"]) \\\n",
    "    .setOutputCols([\"token_features\"]) \\\n",
    "    .setOutputAsArray(True) \\\n",
    "    .setCleanAnnotations(False)\n",
    "\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"token_features\", outputCol=\"rawFeatures\", numFeatures=1000)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5)\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol = \"Category\", outputCol = \"label\")\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.0)\n",
    "\n",
    "label_to_stringIdx = IndexToString(inputCol=\"label\", outputCol=\"sms_class\")\n",
    "\n",
    "nlp_pipeline = Pipeline(\n",
    "    stages=[document_assembler, \n",
    "            tokenizer,\n",
    "            normalizer,\n",
    "            stopwords_cleaner, \n",
    "            stemmer, \n",
    "            finisher,\n",
    "            hashingTF,\n",
    "            idf,\n",
    "            label_stringIdx,\n",
    "            lr,\n",
    "            label_to_stringIdx])\n",
    "\n",
    "nlp_model = nlp_pipeline.fit(trainingData)\n",
    "\n",
    "processed = nlp_model.transform(testData)\n",
    "\n",
    "processed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-----+----------+---------+\n",
      "|             Message|Category|label|prediction|sms_class|\n",
      "+--------------------+--------+-----+----------+---------+\n",
      "|\"A Boy loved a ga...|     ham|  0.0|       0.0|      ham|\n",
      "|\"A boy was late 2...|     ham|  0.0|       0.0|      ham|\n",
      "|\"A cute thought f...|     ham|  0.0|       0.0|      ham|\n",
      "|\"A swt thought: \"...|     ham|  0.0|       0.0|      ham|\n",
      "|\"Beautiful Truth ...|     ham|  0.0|       0.0|      ham|\n",
      "|\"Beautiful Truth ...|     ham|  0.0|       0.0|      ham|\n",
      "|\"Best line said i...|     ham|  0.0|       0.0|      ham|\n",
      "|\"Do 1 thing! Chan...|     ham|  0.0|       0.0|      ham|\n",
      "|\"Edison has right...|     ham|  0.0|       0.0|      ham|\n",
      "|\"Ever green quote...|     ham|  0.0|       0.0|      ham|\n",
      "|\"Gumby's has a sp...|     ham|  0.0|       0.0|      ham|\n",
      "|\"Happy or sad , o...|     ham|  0.0|       0.0|      ham|\n",
      "|\"Height of \"\"Oh s...|     ham|  0.0|       0.0|      ham|\n",
      "|\"I just lov this ...|     ham|  0.0|       0.0|      ham|\n",
      "|\"I'm not smoking ...|     ham|  0.0|       0.0|      ham|\n",
      "|\"Life is nothing ...|     ham|  0.0|       0.0|      ham|\n",
      "|\"Once a fishrman ...|     ham|  0.0|       0.0|      ham|\n",
      "|\"Response is one ...|     ham|  0.0|       0.0|      ham|\n",
      "|\"Single line with...|     ham|  0.0|       0.0|      ham|\n",
      "|\"Storming msg: We...|     ham|  0.0|       0.0|      ham|\n",
      "+--------------------+--------+-----+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed.select(\"Message\",\"Category\",\"label\",\"prediction\",\"sms_class\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.961491\n",
      "Test Error = 0.0385093 \n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(processed)\n",
    "print(\"Accuracy = %g\" % (accuracy))\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
